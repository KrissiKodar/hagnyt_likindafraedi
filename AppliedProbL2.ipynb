{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1043fc-f59c-4df4-996f-359e3c366ade",
   "metadata": {},
   "source": [
    "# Lecture 2 - Conditional probability, the Bayes Rule and independence\n",
    "\n",
    "## L2.1 Conditional Probability\n",
    "\n",
    "Conditional probability is one of the most important concepts in probability theory: What is the probability of an event, given that another event has occured. E.g., what is the probability of rolling a 2 given that the roll is an even number.\n",
    "\n",
    "To introduce the concept, let's consider the following example taken from The Book of Why by J. Pearl. We have twelve customers in a teahouse who buy tea or scones or nothing. The table below shows the purchases of the 12 customers:\n",
    "\n",
    "<table>\n",
    "    <tr><th>CustomerID</th><th>Tea</th><th>Scones</th></tr>\n",
    "    <tr><th>1</th><th>Yes</th><th>Yes</th></tr>\n",
    "    <tr><th>2</th><th>No</th><th>Yes</th></tr>\n",
    "    <tr><th>3</th><th>No</th><th>No</th></tr>\n",
    "    <tr><th>4</th><th>No</th><th>No</th></tr>\n",
    "    <tr><th>5</th><th>Yes</th><th>Yes</th></tr>\n",
    "    <tr><th>6</th><th>Yes</th><th>No</th></tr>\n",
    "    <tr><th>7</th><th>Yes</th><th>No</th></tr>\n",
    "    <tr><th>8</th><th>Yes</th><th>Yes</th></tr>\n",
    "    <tr><th>9</th><th>Yes</th><th>No</th></tr>\n",
    "    <tr><th>10</th><th>Yes</th><th>No</th></tr>\n",
    "    <tr><th>11</th><th>No</th><th>No</th></tr>\n",
    "    <tr><th>12</th><th>Yes</th><th>Yes</th></tr>\n",
    "    </table>\n",
    "\n",
    "We see that 8 customers ordered tea, so $P(T) = 8/12 = 2/3$. Similarly, $P(S) = 5/12$.\n",
    "Customers [1,2,5,8,12] ordered scones, and of these, customers [1,5,8,12] ordered both tea and scones. What should the probability of $T$ given $S$ be? It makes sense that these are 4 out of a total of 5, or 4/5, i.e., $P(T|S) = 4/5$. \n",
    "\n",
    "To get to the conditional probability, we need to reduce the full sample space (12 members), to the event that we condition on (S with 5 members). Now, S becomes our universe an we simply count and divide with the total number in S instead of using the total number on $\\Omega$. Of course, S needs to have $P(S)>0$. To move between the two worlds, we use $P(S) = 5/12$.\n",
    "\n",
    "Thus, the unconditional probability of finding a customer who bought both tea and scones is $P(S \\cap T) = P(S)P(T|S) = \\frac{5}{12} \\frac{4}{5} = \\frac{4}{12} = \\frac{1}{3}$\n",
    "\n",
    "This leads us to the definition of the conditional probability. If $P(S)>0$, then the conditional probability is defined to be \n",
    "\n",
    "$$P(T|S) = \\frac{P(T \\cap S)}{P(S)}$$\n",
    "\n",
    "It turns out, that $P(T|S)$ is a probability measure in its own right when restricted to subsets of S.\n",
    "\n",
    "### Excercise: Find P(S|T) in the teahouse example.\n",
    "\n",
    "One of the most useful application of conditional probilities is the total probability rule. Start by defining a **partition**:\n",
    "\n",
    "$B_1, .. , B_k$ is a partition, i.e., a collection of disjoint subsets whose union is $\\Omega$\n",
    "\n",
    "## Law of total probability \n",
    "\n",
    "$$P(A) = \\sum_{i=1}^{k}{P(A \\cap B_i)} = \\sum_{i=1}^{k}{P(A|B_i)P(B_i)}.$$\n",
    "\n",
    "#### Exercise. Ari flips 3 fair coins and Bryndis flips 2. Ari wins if the number of Heads he gets is more than the number Bryndis gets. What is the probability that Ari wins?\n",
    "\n",
    "Hint: Use a partition $B_i$ on the number of heads that Bryndis gets (0, 1 or 2), and the law of total probability.\n",
    "\n",
    "Another very useful rule based on conditional probability is the **multiplication rule**. This is what probability trees are based on. \n",
    "\n",
    "If $A = A_1 \\cap A_2 \\cap ... \\cap A_k$, with $P(A_i)>0$ for all $i$, then\n",
    "\n",
    "$$P(A) = P(A_1)P(A_2|A_1)P(A_3|A_1 \\cap A_2) ... P(A_k|A_1 \\cap A_2 \\cap ... \\cap A_{k-1})$$\n",
    "\n",
    "An example of its use is flipping 3 coins as in the last excercise.\n",
    "\n",
    "Another quite interesting example comes from Causal Inference In Statistics by Pearl. Consider the plausibility of the statement\n",
    "\n",
    "$$P(Cloudy \\cap No Rain \\cap Dry Pavement \\cap Slipery Pavement) = 0.23$$\n",
    "\n",
    "Is this plausible? At first, it seems very hard to assess, but the multiplication rule helps us out.\n",
    "\n",
    "$$P(Cloudy) = 0.5$$ might be reasonable, and $$P(No Rain|Cloudy) = 0.75$$ is probably not too far from the truth. One could speculate that $$P(Dry Pavement|No Rain) = 0.9$$ and $$P(Slippery Pavement|Dry Pavement) = 0.05$$ (probably quite low). Using these numbers, we get that  \n",
    "$$P(Cloudy \\cap No Rain \\cap Dry Pavement \\cap Slipery Pavement) = 0.5x0.75x0.9x0.05$$ which is about 2%... So, the statement is not plausible at all. This is a useful common sense tool that one can apply in situations where the answer might not be so obvious.\n",
    "\n",
    "Let's move on to a famous example called the **Monty Hall problem**. It is based on an old American game show where you are told that a prize can be found behind one of three closed doors in front of you. The game has two steps. In the first step, you point to a door. Then, the game host opens one of the remaining two doors after making sure that the price is not behind it. The second step involves you either sticking to your orginal choice or switch to the other unopened door. You win of the price is behind the door you end up choosing. The question is which strategy is better.\n",
    "\n",
    "1. What is the probability of you winning if you stick to the initial chosen door?\n",
    "2. What is the probabability of you winning if you switch doors?\n",
    "\n",
    "Clearly, the answer to 1. is 1/3. You just choose one door out of 3.\n",
    "\n",
    "For 2, many people argue that the two unopened doors are the same so the probability should be 1/2 so there is no point in switching. However, using conditional probability, we can compute the answer:\n",
    "\n",
    "To simpify the exposure, letÂ´s assume that we always choose door nr. 1. The situation are as follows (the headings refer to the doors, and X marks the location of the price):\n",
    "\n",
    "<table>\n",
    "    <tr><th>Case</th><th>1</th><th>2</th><th>3</th></tr>\n",
    "    <tr><td>1</td><td>X</td><td> </td><td> </td></tr>\n",
    "    <tr><td>2</td><td> </td><td>X</td><td> </td></tr>\n",
    "    <tr><td>3</td><td> </td><td> </td><td>X</td></tr>\n",
    "</table>\n",
    "\n",
    "Now, using the law of total probability:\n",
    "\n",
    "$$P(\\text{Win}) = P(\\text{Win}|1)*P(1) + P(\\text{Win}|2)*P(2) + P(\\text{Win}|3)*P(3)$$\n",
    "\n",
    "We assume that $P(1) = P(2) = P(3) = 1/3$.\n",
    "\n",
    "$$P(\\text{Win}|1) = 0$$\n",
    "$$P(\\text{Win}|2) = 1$$\n",
    "$$P(\\text{Win}|3) = 1$$\n",
    "\n",
    "\n",
    "Thus, \n",
    "\n",
    "$$P(\\text{Win}) = 0*1/3 + 1*1/3 +1*1/3 = 2/3$$\n",
    "\n",
    "The answer is also quite obvious when we think about in a different way. Namely, you will always win if you switch unless you happened to pick the door with the price behind it in the first step. Thus, the probability of winning is 1 - 1/3 = 2/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "33330ebb-a75c-4eb6-8014-fb8da836d167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wins:  4  ratio  0.4\n"
     ]
    }
   ],
   "source": [
    "#Monty Hall problem\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "number_of_doors = 3\n",
    "N = 10 #1000\n",
    "wins = 0\n",
    "\n",
    "switch = False #Stategy, switch doors or not\n",
    "\n",
    "for i in range(N):\n",
    "    actual_door = np.random.randint(1,number_of_doors+1)\n",
    "    chosen_door = np.random.randint(1,number_of_doors+1)\n",
    "    #Open a door - find which door remains closed\n",
    "    #print(\"Actual: \", actual_door)\n",
    "    #print(\"Original chosen: \", chosen_door)\n",
    "    \n",
    "    if actual_door == chosen_door:\n",
    "        #Closed door is one or the other - chosen at random\n",
    "        remaining_doors = [i for i in range(1,(number_of_doors+1)) if i != actual_door]\n",
    "        closed_door = np.random.choice(remaining_doors)\n",
    "    else: #Open the remaining door, which is not \n",
    "        closed_door = actual_door\n",
    "        \n",
    "    #print(\"Remaining closed door: \", closed_door)\n",
    "    #print()\n",
    "    \n",
    "    #Switch or not\n",
    "    if switch:\n",
    "        wins += (closed_door == actual_door)\n",
    "    else:\n",
    "        wins += (chosen_door == actual_door)\n",
    "\n",
    "print(\"Number of wins: \", wins, \" ratio \", wins/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d29a92-b3da-4633-b891-76915b123401",
   "metadata": {},
   "source": [
    "## L2.1 The Bayes Rule\n",
    "\n",
    "The famous Bayesian formula is a way to move from P(A|B) to P(B|A), which is often very useful as finding one might be simple, whereas finding the other directly might be more challenging. The formula can be found by re-arranging the definition of the conditional probability:\n",
    "\n",
    "$$P(A|B)P(B) = P(A \\cap B) = P(B|A)P(A)$$\n",
    "\n",
    "or\n",
    "\n",
    "$$P(B|A) = \\frac{P(B)}{P(A)}P(A|B)$$\n",
    "\n",
    "In practice, one often needs to use the law of total probability to find P(B) in the denominator. Here is one example:\n",
    "\n",
    "### Example: the false positive puzzle\n",
    "\n",
    "A test for a certain rare disease is assumed to be correct 95% of the time, i.e., if a person has the disease, the test result is positive with probability 0.95, and if the person does not have the disease, the test result is negative with probability 0.95. A random person drawn from a certain population has a probability of 0.001 of having the disease. Given that the person just tested positive, what is the probability of having the disease?\n",
    "\n",
    "Let's say that $D$ is the event that the person as the disease, and thus $\\bar{D}$ is the event that person does not have the disease. Let $T$ be the event of a positive test and thus $\\bar{T}$ is the event of a negative test. Then, we are told that $P(T|D) = P(\\bar{T}|\\bar{D}) = 0.95$ and $P(D) = 0.001$. We are asked to calculate $P(D|T)$.\n",
    "\n",
    "Since we have the opposite, we use the Bayes rule:\n",
    "\n",
    "$$P(D|T) = \\frac{P(D)}{P(T)}P(T|D)$$\n",
    "\n",
    "As is often the case, we are not given $P(T)$ directly, but we can find it using the given data and the law of total probability:\n",
    "\n",
    "$$P(T) = P(T|D)P(D) + P(T|\\bar{D})P(\\bar{D}) = 0.95*0.001 + 0.05*0.999 = 0.0509$$\n",
    "\n",
    "and thus\n",
    "\n",
    "$$P(D|T) = \\frac{P(D)}{P(T)}P(T|D) = \\frac{0.001}{0.0509}0.95 = 0.0187$$\n",
    "\n",
    "Surprise! Test is positive but it is only 2% chance that you actually have the disease. According to the Economist, 80% of those questioned at a leading American hospital thought the answer was 95%..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77cefd-0687-433b-bf64-4de911e05312",
   "metadata": {},
   "source": [
    "## L2.2 Independence\n",
    "\n",
    "An event A is **independent** of B if\n",
    "\n",
    "$$P(A|B) = P(A)$$\n",
    "\n",
    "i.e., the knowledge that B has occured does not change the probability of A occuring. A more general definition, which also works when $P(B) = 0$, is to say that two events are independent if\n",
    "\n",
    "$$P(A \\cap B) = P(A)P(B)$$\n",
    "\n",
    "This means that the probability of the events happing at the same time is the product of the probabilities. One can use the definition of conditional proability to see that the definitions agree when $P(B) \\ne 0$. Here are couple of examples:\n",
    "\n",
    "Flip two coins. A = first coin is Head, B = second coin is Head. $P(A \\cap B) = 1/4 = 1/2*1/2 = P(A)P(B)$, so independent events.\n",
    "\n",
    "Pick a card from a deck of 52 cards. A = Spade, B = Ace. $P(A \\ cap B) = 1/52 = 1/4*1/13 = P(A)P(B)$ so independent events.\n",
    "\n",
    "Pick two cards from the deck. A = first card is a spade, B = second card is a spade. $P(A \\cap B) = \\frac{13}{52}\\frac{12}{52} \\ne 1/4*1/4 = P(A)P(B)$ so dependent events.\n",
    "\n",
    "The definition can be generalized to number of events, and we can say that the events $A_1, A_2, ..., A_n$ are **pairwise independent** if for any combinition $1 \\le i_1 < i_2 < ... < i_k \\le n$\n",
    "$$P(A_{i_1} \\cap A_{i_2} \\cap ... \\cap A_{i_k}) = P(A_{i_1}) P(A_{i_2})... P(A_{i_k})$$\n",
    "\n",
    "The concept of independence is often used in probability trees. If the events are independent, we can move up the tree by multiplying the branches together.\n",
    "\n",
    "### Exercise. Consider 3 tosses of a coin where the P(H) = p. Draw this experiment up as a tree.\n",
    "\n",
    "Now that we have the tree, let's aggregate the probabilities for the number of heads in the 3 tosses. These can be 0, 1, 2, and 3, and their probabilities are:\n",
    "\n",
    "$$P(0) = (1-p)^3, P(1) = 3p(1-p)^2, P(2) = 3p^2(1-p)^2, P(3) = p^3$$\n",
    "\n",
    "Looks like the terms in the expansion of $((1-p) + p)^3$. \n",
    "\n",
    "This pattern generalizes when we want to count the number of success in $n$ trials:\n",
    "\n",
    "$$P(k) = \\binom{n}{k}p^k(1-p)^{n-k}$$ \n",
    "\n",
    "### Exercise. A die is rolled 8 times. What is the probability that we will get exactly two 3's?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7292e09c-ad3d-41e3-bbb3-caa1fc95c859",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probability:  0.104412\n",
      "Theoretical probability = 0.10419048163389727\n"
     ]
    }
   ],
   "source": [
    "from math import factorial\n",
    "\n",
    "#Monte Carlo for the binomial\n",
    "np.random.seed(42)\n",
    "\n",
    "N = 1000000\n",
    "n = 8\n",
    "k = 3\n",
    "\n",
    "success = 0\n",
    "\n",
    "for i in range(N):\n",
    "    sample = np.random.choice(range(1, 7), size=n, replace=True)\n",
    "    if list(sample).count(3) == k:\n",
    "        success += 1\n",
    "\n",
    "print(\"Estimated probability: \", success/N)\n",
    "prob = (factorial(n)/(factorial(k)*factorial(n-k)))*(1/6)**k*(1-1/6)**(n-k)\n",
    "print(f\"Theoretical probability = {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a242dc1a-7969-42dc-b007-2b68d1b8486f",
   "metadata": {},
   "source": [
    "Another important distribution is the geometric distribution. Suppose we roll a die repeatedly until a 6 occurs, and let N be the number of times we roll the die. What is $P(N=1)$? $P(N=2)$? ... $P(N=k)$?\n",
    "\n",
    "The geometric distribution is\n",
    "\n",
    "$P(N=k) = (1-p)^{k-1}p$ for $k=1,2, ...$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ad2929eb-aa8f-4c99-a97a-c24efb5495ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probability P(N=1):  0.16684\n",
      "Estimated probability P(N=2):  0.14038\n",
      "Estimated probability P(N=3):  0.11574\n",
      "Estimated probability P(N=4):  0.09522\n",
      "Estimated probability P(N=5):  0.0814\n",
      "Estimated probability P(N=6):  0.06796\n",
      "Estimated probability P(N=7):  0.05506\n",
      "Estimated probability P(N=8):  0.04676\n",
      "Estimated probability P(N=9):  0.03736\n",
      "Estimated probability P(N=10):  0.03422\n"
     ]
    }
   ],
   "source": [
    "#Monte Carlo for the geometric\n",
    "np.random.seed(42)\n",
    "\n",
    "N = 50000\n",
    "\n",
    "for k in range(1,11): #1, 2, ..., 10\n",
    "    success = 0\n",
    "    for i in range(N):\n",
    "        sample = np.random.choice(range(1, 7), size=k, replace=True)\n",
    "        if (list(sample).count(6) == 1) and (sample[-1] == 6):\n",
    "            success += 1\n",
    "\n",
    "    print(f\"Estimated probability P(N={k}): \", success/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f159554-93fe-4266-8e88-adc4b2e5f8e7",
   "metadata": {},
   "source": [
    "We then have the Hypergeometric distribution. Suppose we have an urn with $n$ balls and $m$ of them are blue. We select $k$ balls at random (without replacement). What is the probability that $i$ of the selected balls are blue (assuming that $i \\le k$)?\n",
    "\n",
    "There are a total of $\\binom{n}{k}$ ways to choose $k$ balls from an urn of $n$ balls, so this is the size of our sample space, and must go into the denominator. Now, we need to figure out in how many ways can we get $i$ blue balls when we pick $k$ balls from the urn. First of all, there are  $\\binom{m}{i}$ ways to find $i$ balls from selection of $m$ balls. We then also need to choose $k-i$ balls from the remaining $n-m$ balls, so the probability is\n",
    "\n",
    "$$\\frac{\\binom{m}{i}\\binom{n-m}{k-i}}{\\binom{n}{k}}$$\n",
    "\n",
    "Let's find the probability of getting 3 blue balls when selecting 4 balls from an urn of 10 balls with 7 blue balls (i=3, k=4, m=7, n=10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0c8d195a-b25a-4df7-b143-63179028511e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.special\n",
    "\n",
    "scipy.special.binom(7,3)*scipy.special.binom(10-7,4-3)/scipy.special.binom(10,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576494d-259d-4e78-a45a-6da5a6940a07",
   "metadata": {},
   "source": [
    "## Homework problems\n",
    "\n",
    "They can be solved using Monte Carlo and theory. Best to do both.\n",
    "\n",
    "#### Bayes Rule/Law of Total Probability\n",
    "1. Suppose families can only have 1, 2, or 3 children, each with probability 1/3. Joe has no brothers. What is the probability that he is an only child?\n",
    "\n",
    "\n",
    "#### Independence\n",
    "2. a) Consider an experiment involving two successive rolls of a fair 4-sided die (outcomes are 1,2,3,4 for each roll). Are the events:\n",
    "\n",
    "A = {1st roll is a 1} and B = {sum of the two rolls is a 5} independent?\n",
    "\n",
    "b) Suppose we draw two cards out of a deck of 52 cards. Let A = {first card is Ace} and B = {second card is spade}. Are the two events indendent?\n",
    "\n",
    "#### Binomial distribution\n",
    "3. a) Three students each have a probability 1/3 of solving a problem. They don't collaborate and their probabilities of solving the problem are independent from one another. What is the probability that at least one student solves the problem?\n",
    "\n",
    "#### Geometric distribution/Binomial Distribution\n",
    "4. a) How many children must a couple have before the probability of at least two boys is larger than 0.75?\n",
    "\n",
    "b) How many times should you roll a die so that the proability of least one 6 is at least 0.9?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e335a42",
   "metadata": {},
   "source": [
    "# 1. Theory\n",
    "\n",
    "$X$: Joe is an only child\n",
    "\n",
    "$Y$: Joe has no brothers\n",
    "\n",
    "$P(X|Y)$: Probability that Joe is an only child given that he has no brothers. \n",
    "\n",
    "$P(X|Y) = \\frac{P(Y|X)P(X)}{P(Y)}$ but $P(Y|X) = 1$ so $P(X|Y) = \\frac{P(X)}{P(Y)}$\n",
    "\n",
    "$P(X) = \\frac{1}{3} \\cdot \\frac{1}{2} = \\frac{1}{6}$\n",
    "\n",
    "$P(X) = \\frac{1}{3} \\cdot \\frac{1}{2} + \\frac{1}{3} \\cdot \\frac{1}{2} +\\frac{1}{3} \\cdot \\frac{3}{8} = \\frac{11}{24}$\n",
    "\n",
    "$\\frac{P(X)}{P(Y)} = \\frac{1/6}{11/24} = \\frac{4}{11} = 36.3636\\%$\n",
    "\n",
    "# 1. Monte Carlo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "429e77cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_n_children = 3\n",
      "n_childs = [1 2 3]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probabilities: \n",
      "Probability boy and only child:  0.166976\n",
      "Probability at most one boy  0.458939\n",
      "Probability only child given no brothers:  0.3638304872760868\n"
     ]
    }
   ],
   "source": [
    "#Monte Carlo \n",
    "#np.random.seed(42)\n",
    "\n",
    "max_n_children = 3\n",
    "n_childs = np.arange(max_n_children) + 1\n",
    "\n",
    "print(f\"max_n_children = {max_n_children}\")\n",
    "print(f\"n_childs = {n_childs}\\n\")\n",
    "\n",
    "only_child_and_boy = 0\n",
    "at_most_one_boy = 0\n",
    "\n",
    "N = 1000000\n",
    "\n",
    "for i in range(N):\n",
    "    n_children = (np.random.choice(n_childs, size=1, replace=True))[0]\n",
    "    children = np.random.choice(range(0, 2), size=n_children, replace=True) # flip coin for children\n",
    "    if list(children).count(1) == 1:\n",
    "        at_most_one_boy += 1\n",
    "    if list(children).count(1) == 1 and len(children) == 1:\n",
    "        only_child_and_boy += 1\n",
    "\n",
    "\n",
    "print(\"Estimated probabilities: \")\n",
    "\n",
    "print(\"Probability boy and only child: \", only_child_and_boy/N)\n",
    "\n",
    "print(\"Probability at most one boy \", at_most_one_boy/N)\n",
    "\n",
    "print(\"Probability only child given no brothers: \", only_child_and_boy/at_most_one_boy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64261bb8",
   "metadata": {},
   "source": [
    "# 2. Theory \n",
    "\n",
    "### a)\n",
    "\n",
    "The probability of first throw being $1$ is $P(A) = 1/4$\n",
    "\n",
    "The probability of the sum of the two rolls being 5 is also $P(B) = 1/4$\n",
    "\n",
    "The probability of the sum of the two rolls being 5 given that the first throw was $1$ is $P(B|A) = 1/4$\n",
    "\n",
    "So $P(B|A) = P(B)$ and the events are independent\n",
    "\n",
    "\n",
    "### b)\n",
    "\n",
    "The probability of A $P(A) = 1/52$\n",
    "\n",
    "The probability of B $P(B) = 4/51$ or $P(B) = 3/51$ depending on if the first ace card was a spade, obviously dependent.\n",
    "\n",
    "# 2. Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "9a31ff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probabilities: \n",
      "Probability A 0.25167\n",
      "Probability B 0.25176\n",
      "Probability A * Probability B 0.0633604392\n",
      "Probability both 0.06396\n"
     ]
    }
   ],
   "source": [
    "max_n = 4\n",
    "n_rolls = 2\n",
    "die = np.arange(max_n) + 1\n",
    "\n",
    "N = 100000\n",
    "\n",
    "A = 0\n",
    "B = 0\n",
    "both = 0\n",
    "\n",
    "for i in range(N):\n",
    "    die_rolls = np.random.choice(die, size=n_rolls, replace=True) # throw 1 die\n",
    "    if die_rolls[0] == 1:\n",
    "        A += 1\n",
    "    if sum(die_rolls) == 5:\n",
    "        B += 1\n",
    "    if die_rolls[0] == 1 and sum(die_rolls) == 5:\n",
    "        both += 1\n",
    "        \n",
    "print(\"Estimated probabilities: \")\n",
    "\n",
    "print(\"Probability A\", A/N)\n",
    "\n",
    "print(\"Probability B\", B/N)\n",
    "\n",
    "print(\"Probability A * Probability B\", (A/N)*(B/N))\n",
    "\n",
    "print(\"Probability both\", both/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66736518",
   "metadata": {},
   "source": [
    "# 3. Theory\n",
    "\n",
    "$P(k) = \\binom{n}{k}p^k(1-p)^{n-k}$\n",
    "\n",
    "\n",
    "$n = 3$\n",
    "\n",
    "$k = 1, 2, 3$\n",
    "\n",
    "\n",
    "$P(0) = \\binom{3}{0}(\\frac{1}{3})^0(1-\\frac{1}{3})^{3-0} = (\\frac{2}{3})^{3} = \\frac{8}{27}$\n",
    "\n",
    "So the probability that at least one student solves the problem is $1-P(0) = \\frac{8}{27}=\\frac{19}{27} = 0.70370370...$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed9871",
   "metadata": {},
   "source": [
    "# 4. Theory\n",
    "\n",
    "Binomial distribution: getting exactly $k$ successes in $n$ independent (Bernoulli) trials\n",
    "\n",
    "Geometric distribution: probability that the first occurrence of success requires $k$ independent trials\n",
    "\n",
    "### a)\n",
    "\n",
    "Binomial, probability of at least 2 boys in $n$ trials is $1-p(0)-p(1)$. When is this larger than 0.75?\n",
    "$p(0) = \\frac{n!}{0!(n-0)!}p^0(1-p)^{n-0}=(1-p)^n=q^n$\n",
    "\n",
    "$p(1) =\\frac{n!}{1!(n-1)!}p^1q^{n-1}=p^1q^{n-1}=npq^{n-1}$ \n",
    "\n",
    "$1-p(0)-p(1) = 0.75$ leads to $p(0)+p(1) = 0.25 = q^n + npq^{n-1} = q^n(1+n)$\n",
    "\n",
    "$(1/2)^n(1+n)=0.25$\n",
    "\n",
    "Trials for $n = 1, 2, 3...$ lead to $n=5$ as the number of children that a couble must have before the probability of at least two boys is larger than 0.75.\n",
    "\n",
    "### b)\n",
    "\n",
    "Binomial, $1$ minus the probability of no $6$ in $n$ trials gives the probability of at least one $6$ in $n$ trials.\n",
    "\n",
    "$1-p(0) = 1 - q^n \\geq 0.9$\n",
    "\n",
    "$q^n \\leq 0.1$\n",
    "\n",
    "$n \\geq \\frac{\\ln(0.1)}{\\ln(q)} = \\frac{\\ln(0.1)}{\\ln(5/6)} = 12.63$ So the dice should be rolled $13$ times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
